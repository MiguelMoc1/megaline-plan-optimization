{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Planes Móviles de Megaline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Megaline, una compañía de telecomunicaciones, está buscando optimizar el uso de sus nuevos planes de suscripción: Smart y Ultra. Actualmente, muchos de sus clientes todavía utilizan planes heredados, y Megaline desea desarrollar un modelo de clasificación que pueda analizar el comportamiento de los clientes y recomendarles el plan adecuado.\n",
    "\n",
    "Para este proyecto, utilizaremos datos históricos del comportamiento mensual de los suscriptores que ya han cambiado a los nuevos planes. Estos datos incluirán información sobre el número de llamadas, la duración total de las llamadas, el número de mensajes de texto y el tráfico de Internet utilizado en megabytes (MB). Nuestro objetivo es crear un modelo de clasificación que pueda predecir si un cliente debería utilizar el plan Smart o el plan Ultra con una exactitud mínima de 0.75.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de los Datos\n",
    "\n",
    "Cada observación en el dataset contiene información del comportamiento mensual de un usuario, incluyendo:\n",
    "\n",
    "- `calls`: Número de llamadas\n",
    "- `minutes`: Duración total de las llamadas en minutos\n",
    "- `messages`: Número de mensajes de texto\n",
    "- `mb_used`: Tráfico de Internet utilizado en MB\n",
    "- `is_ultra`: Plan para el mes actual (Ultra - 1, Smart - 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos del Proyecto\n",
    "\n",
    "1. **Explorar y preprocesar los datos**:\n",
    "    - Leer y examinar el archivo de datos.\n",
    "    - Verificar la calidad de los datos: valores nulos, tipos de datos, distribuciones.\n",
    "    - Manejar valores nulos o atípicos si existen.\n",
    "    - Normalizar o estandarizar características si es necesario.\n",
    "    \n",
    "2. **Segmentar los datos en conjuntos de entrenamiento, validación y prueba**:\n",
    "    - Dividir los datos en conjuntos de entrenamiento (60%), validación (20%) y prueba (20%).\n",
    "    \n",
    "3. **Entrenar y evaluar diferentes modelos de clasificación**:\n",
    "    - Probar varios modelos de clasificación: Árbol de Decisión, Bosque Aleatorio, Regresión Logística, entre otros.\n",
    "    - Ajustar hiperparámetros utilizando el conjunto de validación.\n",
    "    - Evaluar el modelo final utilizando el conjunto de prueba.\n",
    "    \n",
    "4. **Realizar una prueba de cordura al modelo**:\n",
    "    - Asegurar que el modelo no esté sobreajustado y funcione bien en situaciones no vistas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar y Examinar los Datos\n",
    "\n",
    "En este paso, cargaremos el archivo de datos `users_behavior.csv` y examinaremos su contenido para entender mejor la estructura y la calidad de los datos. Verificaremos si hay valores nulos y exploraremos las estadísticas descriptivas de las variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "url = 'https://practicum-content.s3.us-west-1.amazonaws.com/datasets/users_behavior.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión Parcial\n",
    "Los datos no contienen valores nulos, lo cual es positivo para nuestro análisis. Las estadísticas descriptivas muestran que las variables tienen diferentes rangos de valores, lo que puede ser relevante para el análisis posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentar los Datos en Conjuntos de Entrenamiento, Validación y Prueba\n",
    "\n",
    "En este paso, segmentaremos los datos en conjuntos de entrenamiento, validación y prueba. El conjunto de entrenamiento se usará para entrenar el modelo, el conjunto de validación para ajustar los hiperparámetros, y el conjunto de prueba para evaluar la calidad final del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 1928\n",
      "Tamaño del conjunto de validación: 643\n",
      "Tamaño del conjunto de prueba: 643\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en características (X) y objetivo (y)\n",
    "X = df.drop(columns=['is_ultra'])\n",
    "y = df['is_ultra']\n",
    "\n",
    "# Dividir datos en conjuntos de entrenamiento (60%), validación (20%) y prueba (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=12345)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Mostrar el tamaño de cada conjunto\n",
    "print(f'Tamaño del conjunto de entrenamiento: {X_train.shape[0]}')\n",
    "print(f'Tamaño del conjunto de validación: {X_valid.shape[0]}')\n",
    "print(f'Tamaño del conjunto de prueba: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión Parcial\n",
    "Los datos han sido segmentados correctamente en conjuntos de entrenamiento, validación y prueba. Esta segmentación nos permitirá entrenar los modelos en el conjunto de entrenamiento, ajustar los hiperparámetros en el conjunto de validación y evaluar el rendimiento final en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar y Evaluar Modelos de Clasificación\n",
    "En este paso, entrenaremos diferentes modelos de clasificación y evaluaremos su rendimiento en el conjunto de validación. Probaremos varios modelos como Decision Tree, Random Forest, y Logistic Regression, ajustando los hiperparámetros para encontrar el mejor rendimiento posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "En esta parte, entrenaremos y evaluaremos un modelo Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Decision Tree accuracy: 0.7854 con hiperparámetros: {'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar el modelo Decision Tree\n",
    "best_dt_accuracy = 0\n",
    "best_dt_params = {}\n",
    "\n",
    "# Probar diferentes valores de max_depth\n",
    "for max_depth in range(1, 11):\n",
    "    dt_model = DecisionTreeClassifier(random_state=12345, max_depth=max_depth)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    dt_predictions = dt_model.predict(X_valid)\n",
    "    dt_accuracy = accuracy_score(y_valid, dt_predictions)\n",
    "    if dt_accuracy > best_dt_accuracy:\n",
    "        best_dt_accuracy = dt_accuracy\n",
    "        best_dt_params = {'max_depth': max_depth}\n",
    "\n",
    "print(f'Mejor Decision Tree accuracy: {best_dt_accuracy:.4f} con hiperparámetros: {best_dt_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "En esta parte, entrenaremos y evaluaremos un modelo Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Random Forest accuracy: 0.8087 con hiperparámetros: {'n_estimators': 40, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar el modelo Random Forest\n",
    "best_rf_accuracy = 0\n",
    "best_rf_params = {}\n",
    "\n",
    "for n_estimators in range(10, 101, 10):\n",
    "    for max_depth in range(1, 11):\n",
    "        rf_model = RandomForestClassifier(random_state=12345, n_estimators=n_estimators, max_depth=max_depth)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        rf_predictions = rf_model.predict(X_valid)\n",
    "        rf_accuracy = accuracy_score(y_valid, rf_predictions)\n",
    "        if rf_accuracy > best_rf_accuracy:\n",
    "            best_rf_accuracy = rf_accuracy\n",
    "            best_rf_params = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "print(f'Mejor Random Forest accuracy: {best_rf_accuracy:.4f} con hiperparámetros: {best_rf_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "En esta parte, entrenaremos y evaluaremos un modelo Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Logistic Regression accuracy: 0.7107 con hiperparámetros: {'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar el modelo Logistic Regression\n",
    "best_lr_accuracy = 0\n",
    "best_lr_params = {}\n",
    "\n",
    "# Probar diferentes valores de max_iter\n",
    "for max_iter in [100, 200, 500, 1000]:\n",
    "    lr_model = LogisticRegression(random_state=12345, max_iter=max_iter)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    lr_predictions = lr_model.predict(X_valid)\n",
    "    lr_accuracy = accuracy_score(y_valid, lr_predictions)\n",
    "    if lr_accuracy > best_lr_accuracy:\n",
    "        best_lr_accuracy = lr_accuracy\n",
    "        best_lr_params = {'max_iter': max_iter}\n",
    "\n",
    "print(f'Mejor Logistic Regression accuracy: {best_lr_accuracy:.4f} con hiperparámetros: {best_lr_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión Parcial\n",
    "Al ajustar los hiperparámetros, el modelo Random Forest con n_estimators igual a 40 y max_depth igual a 8 ha demostrado ser el más preciso en el conjunto de validación con una exactitud de 0.8087. A continuación, seleccionaremos este modelo para evaluar su rendimiento en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccionar el Mejor Modelo y Evaluar en el Conjunto de Prueba\n",
    "En este paso, seleccionaremos el mejor modelo basado en los resultados de la validación y evaluaremos su rendimiento en el conjunto de prueba. Hemos entrenado y evaluado tres modelos diferentes: Decision Tree, Random Forest y Logistic Regression. Basándonos en los resultados de la exactitud, seleccionaremos el modelo Random Forest ya que ha mostrado el mejor rendimiento.\n",
    "\n",
    "Resultados de los Modelos:\n",
    "\n",
    "Decision Tree accuracy: 0.7854\n",
    "\n",
    "Random Forest accuracy: 0.8087\n",
    "\n",
    "Logistic Regression accuracy: 0.7107\n",
    "\n",
    "\n",
    "El modelo Random Forest ha demostrado ser el más preciso en el conjunto de validación, por lo que lo utilizaremos para evaluar el rendimiento en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest test accuracy: 0.7963\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "best_model = RandomForestClassifier(random_state=12345, n_estimators=40, max_depth=8)\n",
    "best_model.fit(X_train, y_train)\n",
    "test_predictions = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f'Random Forest test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión General\n",
    "En este proyecto, hemos desarrollado y evaluado varios modelos de clasificación para predecir si un cliente de Megaline debería ser recomendado para el plan Ultra o Smart basado en su comportamiento de uso. Comenzamos cargando y examinando los datos, luego los segmentamos en conjuntos de entrenamiento, validación y prueba. Entrenamos y evaluamos tres modelos: Decision Tree, Random Forest y Logistic Regression. Finalmente, seleccionamos el modelo Random Forest basado en su rendimiento superior en el conjunto de validación y lo evaluamos en el conjunto de prueba.\n",
    "\n",
    "El modelo Random Forest logró una exactitud de 0.7963 en el conjunto de validación y una exactitud comparable en el conjunto de prueba, superando el umbral de exactitud de 0.75 requerido por Megaline. Esto sugiere que el modelo es efectivo para predecir el plan adecuado para los clientes de Megaline."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1503,
    "start_time": "2024-07-09T18:57:31.049Z"
   },
   {
    "duration": 125,
    "start_time": "2024-07-09T18:57:46.630Z"
   },
   {
    "duration": 27,
    "start_time": "2024-07-09T18:58:08.632Z"
   },
   {
    "duration": 123,
    "start_time": "2024-07-09T18:58:15.484Z"
   },
   {
    "duration": 126,
    "start_time": "2024-07-09T18:58:30.768Z"
   },
   {
    "duration": 127,
    "start_time": "2024-07-09T18:59:44.033Z"
   },
   {
    "duration": 125,
    "start_time": "2024-07-09T19:00:07.978Z"
   },
   {
    "duration": 1631,
    "start_time": "2024-07-09T19:00:21.390Z"
   },
   {
    "duration": 144,
    "start_time": "2024-07-09T19:00:36.108Z"
   },
   {
    "duration": 474,
    "start_time": "2024-07-09T19:01:45.527Z"
   },
   {
    "duration": 481,
    "start_time": "2024-07-09T19:02:15.278Z"
   },
   {
    "duration": 483,
    "start_time": "2024-07-09T19:02:48.380Z"
   },
   {
    "duration": 681,
    "start_time": "2024-07-09T19:05:26.511Z"
   },
   {
    "duration": 484,
    "start_time": "2024-07-09T19:05:28.531Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-09T19:06:38.895Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-09T19:06:55.074Z"
   },
   {
    "duration": 120,
    "start_time": "2024-07-09T19:09:02.121Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-09T19:10:48.862Z"
   },
   {
    "duration": 540,
    "start_time": "2024-07-09T19:11:14.251Z"
   },
   {
    "duration": 32,
    "start_time": "2024-07-09T19:11:37.561Z"
   },
   {
    "duration": 563,
    "start_time": "2024-07-09T19:14:31.209Z"
   },
   {
    "duration": 314,
    "start_time": "2024-07-10T19:41:41.761Z"
   },
   {
    "duration": 1251,
    "start_time": "2024-07-10T19:41:49.902Z"
   },
   {
    "duration": 492,
    "start_time": "2024-07-10T19:41:51.157Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-10T19:41:51.651Z"
   },
   {
    "duration": 113,
    "start_time": "2024-07-10T19:41:51.666Z"
   },
   {
    "duration": 543,
    "start_time": "2024-07-10T19:41:51.784Z"
   },
   {
    "duration": 33,
    "start_time": "2024-07-10T19:41:52.330Z"
   },
   {
    "duration": 545,
    "start_time": "2024-07-10T19:41:52.366Z"
   },
   {
    "duration": 17876,
    "start_time": "2024-07-10T19:42:27.485Z"
   },
   {
    "duration": 102,
    "start_time": "2024-07-10T19:42:54.065Z"
   },
   {
    "duration": 158,
    "start_time": "2024-07-10T19:45:19.260Z"
   },
   {
    "duration": 165,
    "start_time": "2024-07-10T19:45:40.440Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-10T19:45:44.803Z"
   },
   {
    "duration": 485,
    "start_time": "2024-07-10T19:45:44.812Z"
   },
   {
    "duration": 14,
    "start_time": "2024-07-10T19:45:45.301Z"
   },
   {
    "duration": 107,
    "start_time": "2024-07-10T19:45:45.318Z"
   },
   {
    "duration": 17489,
    "start_time": "2024-07-10T19:45:45.429Z"
   },
   {
    "duration": 117,
    "start_time": "2024-07-10T19:46:02.923Z"
   },
   {
    "duration": 173,
    "start_time": "2024-07-10T19:46:03.042Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
